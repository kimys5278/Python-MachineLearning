# -*- coding: utf-8 -*-
"""머신러닝 당뇨병예측

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1brpprsj2OQ8OWzR9n35Ae5koU2PDZgBm
"""

# 구글연결
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd 
import matplotlib.pyplot as plt 
import numpy as np 
import seaborn as sns 

df = pd.read_csv('/content/drive/MyDrive/인디언/diabetes.csv') 
df.info()

df.head(5)

df.describe()

sns.pairplot(df)

sns.boxplot(y="Pregnancies", data=df)

#- 당뇨병 여부에 따른 임신 횟수를 살펴봣더니, 임신 횟수가 적을 수록 당뇨병 발병이 적은걸 알수 있다.
sns.boxplot(x="Outcome", y="Pregnancies", data=df)

sns.boxplot(x="Outcome", y="BMI", data=df)

sns.boxplot(x="Outcome", y="Insulin", data=df)

sns.boxplot(x="Outcome", y="SkinThickness", data=df)

#나이대별 발병 여부는 어떨까? -> 젊은 층보다 중고령층인 경우 발병확률이 높음을 알 수 있다.

plt.figure(figsize=(12,6)) 
sns.barplot(x="Age", y="Outcome", data=df)

# 결측치 처리
# 전처리 단계서 사용할 라이브러리 임포트
# 결측치를 확인해보니 존재하지 않는다.

from sklearn.preprocessing import LabelEncoder 
from sklearn.preprocessing import StandardScaler 
from sklearn.model_selection import train_test_split 
df.isnull().sum()

df.describe()

# 전체768행 데이터중 이상치들 갯수 포합시켜도 40개정도 확인
#이상치 제거
cols = df.columns 
print(df.shape) 
for col in cols: 
  mean = df[col].mean() 
  std = df[col].std() 
  threshold = mean + 3 * std 
  n_outlier = np.sum(df[col] > threshold) 
  print(col + ". num of outlier : "+str(n_outlier))


  

print("768 -> 727")

#이상치 제거, 스케일링 처리
cols = df.columns 
print("before drop outlier : {}".format(df.shape)) 
for col in cols: 
  mean = df[col].mean() 
  std = df[col].std() 
  threshold = mean + 3 * std 
  n_outlier = np.sum(df[col] > threshold) 
  #print(df[df[col] > threshold]) 
  df.drop(df[df[col] > threshold].index[:], inplace=True) 
  
  df.dropna() 
  print("after drop outlier : {}".format(df.shape))

#피처스케일링
X = df.loc[:, df.columns != "Outcome"] 
y = df.loc[:, df.columns == "Outcome"] 
scaler = StandardScaler() 
X_scaled = scaler.fit_transform(X) 
print(X_scaled[:,:6])

print("모든 데이터들이 표준 정규 분포를 따르는 값들로 변화 됨")

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

def fit_clasifiers(gs_clfs, X, y):
    for clf in gs_clfs:
        print(X.shape)
        clf.fit(X, y)
    
def show_gridsearch_result(gs_clfs):
    estimators = []
    scores = []
    params = []
    for clf in gs_clfs:
        estimators.append(str(clf.estimator))
        scores.append(clf.best_score_)
        params.append(clf.best_params_)


    for i, val in enumerate(estimators):
        print(val)
        print(scores[i])
        print(params[i])
        
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
svc = SVC(probability=True)
rf = RandomForestClassifier()

param_lr = {"penalty":["l1", "l2", "elasticnet", "none"]}
param_svc = {"kernel":["linear", "poly", "rbf", "sigmoid"]}
param_tree = {
    "max_depth" : [3, 4, 5, 6],
    "min_samples_split" : [2, 3]
}
gs_svc = GridSearchCV(svc, param_grid=param_svc, cv=5, refit=True
                       )
gs_rf = GridSearchCV(rf, param_grid=param_tree, cv=5, refit=True)

gs_clfs = [gs_svc,gs_rf]
fit_clasifiers(gs_clfs, X_train, y_train)
show_gridsearch_result(gs_clfs)

#SVM

from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score
from sklearn.metrics import recall_score, precision_score,roc_curve
from sklearn.metrics import precision_recall_curve

def show_metrics(y_test, y_pred):
    confusion = confusion_matrix(y_test, y_preds)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    print(confusion)
    print("정확도 : {}".format(accuracy))
    print("정밀도 : {}".format(precision))
    print("재현율 : {}".format(recall))

def show_precision_recall_curve(y_test,prob_positive_pred):
    precisions, recalls, thresholds = precision_recall_curve(y_test, prob_positive_pred)
    print("th val : {}".format(thresholds[:4]))
    print("precision val : {}".format(precisions[:4]))
    print("recalls val : {}".format(recalls[:4]))

    df = {
        "thresholds":thresholds, 
          "precisions":precisions[:-1], 
          "recalls":recalls[:-1]
    }
    df = pd.DataFrame.from_dict(df)

    sns.lineplot(x="thresholds", y="precisions", data=df)
    sns.lineplot(x="thresholds", y="recalls", data=df)

    


y_preds = gs_svc.predict(X_test)
pred_prob = gs_svc.predict_proba(X_test)
show_metrics(y_test, y_preds)
y_preds = np.concatenate([pred_prob, y_preds.reshape(-1, 1)], axis=1)
prob_positive_pred = y_preds[:, 1]

show_precision_recall_curve(y_test,prob_positive_pred)



from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score
from sklearn.metrics import recall_score, precision_score,roc_curve
from sklearn.metrics import precision_recall_curve

def show_metrics(y_test, y_pred):
    confusion = confusion_matrix(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    print(confusion)
    print("정확도 : {}".format(accuracy))
    print("정밀도 : {}".format(precision))
    print("재현율 : {}".format(recall))

def show_precision_recall_curve(y_test,prob_positive_pred):
    precisions, recalls, thresholds = precision_recall_curve(y_test, prob_positive_pred)
    print("th val : {}".format(thresholds[:4]))
    print("precision val : {}".format(precisions[:4]))
    print("recalls val : {}".format(recalls[:4]))

    df = {
        "thresholds":thresholds, 
          "precisions":precisions[:-1], 
          "recalls":recalls[:-1]
    }
    df = pd.DataFrame.from_dict(df)

    sns.lineplot(x="thresholds", y="precisions", data=df)
    sns.lineplot(x="thresholds", y="recalls", data=df)
 
    


y_predr = gs_rf.predict(X_test)
pred_prob = gs_rf.predict_proba(X_test)
show_metrics(y_test, y_predr)
y_predr = np.concatenate([pred_prob, y_predr.reshape(-1, 1)], axis=1)
prob_positive_pred = y_predr[:, 1]

show_precision_recall_curve(y_test,prob_positive_pred)

def show_roc_curve(y_test,prob_positive_pred):
    fpr, tpr, thresholds = roc_curve(y_test,prob_positive_pred)

    print("fpr val : {}".format(fpr[:4]))
    print("tpr val : {}".format(tpr[:4]))
    print("thresholds val : {}".format(thresholds[:4]))

    df = {"threshold":thresholds, "fpr":fpr, "tpr":tpr}
    df = pd.DataFrame.from_dict(df)
    sns.lineplot(x="fpr", y="tpr", data=df)

    roc_score = roc_auc_score(y_test, prob_positive_pred)
    print(roc_score)

show_roc_curve(y_test,prob_positive_pred)

def show_lower_outlier(df, stdev=3, show_total=False):

    # lower bound outliers
    cols = df.columns
    print(df.shape)
    for col in cols:
        #std
        mean = df[col].mean()
        std = df[col].std()
        threshold = mean - stdev * std
        n_outlier = np.sum(df[col] < threshold)
        print(col + ". mean : "+str(round(mean,3))+", num of outlier : "+str(n_outlier))
        if (show_total == True) & (n_outlier != 0):
            print(df.loc[(df[col] < threshold),col][:5])
        
        print("   -> cnt of zero : " + str(np.sum(df[col] == 0))+"\n")

show_lower_outlier(df,show_total=True)

df.loc[ df.loc[:, "Insulin"] == 0 , "Insulin"] = df["Insulin"].mean()
df.loc[ df.loc[:, "SkinThickness"] == 0 , "SkinThickness"] = df["SkinThickness"].mean()
df.loc[ df.loc[:, "BloodPressure"] == 0 , "BloodPressure"] = df["SkinThickness"].mean()

show_lower_outlier(df,show_total=True)